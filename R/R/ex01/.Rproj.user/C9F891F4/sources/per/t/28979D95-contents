---
title: "Descriptive Statistics and Graphics"
author: "Yoseph"
date: '2020 8 1 '
output: html_document
---

# Descriptive statistics consist of describing simply the data using some summary statistics and graphics.

***

>Here, we’ll use the built-in R data set named **iris**.

```{r chunk_1, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Store the data in the variable my_data
my_data <- iris

library(dplyr)

set.seed(1234)#난수생성기, 재현성을 위해 써야함. 무작위성 함수를 이용할 때
#set.seed를 사용하지 않으면 다시 이 함수를 수행할 때 매번 다른 것이 나온다.
sample_n(tbl = my_data, size = 10, replace = F)
```
#replace True면 복원 추출, 뽑았던 것 또 뽑겠다. False면 비복원 추출


***
# R functions for computing descriptive statistics

```{r chunk_2, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
funcs <- data.frame(
  seq = seq(1:10),
  Functions = c("mean()", "sd()", "var()", "min()", "maximum()", "median()", "range()", "quantile()", "summary()", "IQR()"),
  Description = c("Mean", "Standard deviation", "Variance", "Minimum", "Maximum", "Median", "Range of values (minimum and maximum)", "Sample quantiles", "Generic function", "Interquartile range")
)
```

```{r chunk_3, results='asis', echo=FALSE, message=FALSE}
knitr::kable(funcs)
```

>The function `mfv{modeest}`, for **most frequent value**, can be used to find the statistical mode of a numeric vector. 

***

## Measure of central tendency: mean, median, mode

### Descriptive statistics for a single group

Roughly speaking, the **central tendency** measures the “**average**” or the “**middle**” of your data.  
The most commonly used measures include:  

  - The **mean**: the average value. It’s sensitive to outliers.  
  - The **median**: the middle value. It’s a robust alternative to mean.  
  - The **mode**: the most frequent value.  

In R,  

  - The function `mean{base}` and `median{stats}` can be used to compute the mean and the median, respectively.  
  - The function `mfv{modeest}` can be used to compute the mode of a variable.  

The R code below computes the `mean`, `median` and the `mode` of the variable **Sepal.Length** in my_data data set:  

```{r chunk_4, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the mean value
mean(my_data$Sepal.Length)
```

```{r chunk_5, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the median value
median(my_data$Sepal.Length)
```

```{r chunk_6, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the mode

# install.packages("modeest")
library(modeest)

mfv(my_data$Sepal.Length)
```

***

## Measure of variablity  

### Measures of variability gives how “spread out” the data are.  

***

#### (1) Range: minimum & maximum
  - **Range** corresponds to biggest value minus the smallest value. It gives you the full spread of the data.  

```{r chunk_7, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the minimum value
min(my_data$Sepal.Length)
```

```{r chunk_8, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the maximum value
max(my_data$Sepal.Length)
```

```{r chunk_9, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Range
range(my_data$Sepal.Length)
``` 

***

#### (2) Interquartile range  

Recall that, quartiles divide the data into 4 parts. Note that, the interquartile range (IQR) - corresponding to the difference between the first and third quartiles - is sometimes used as a robust alternative to the standard deviation.  

  * R function:  
  
`quantile(x, probs = seq(0, 1, 0.25))`  

    + x: numeric vector whose sample quantiles are wanted.  
    + probs: numeric vector of probabilities with values in [0,1].  
    
    
  * Example:
```{r chunk_10, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
quantile(my_data$Sepal.Length)
```  
>By default, the function returns the **minimum**, the **maximum** and **three quartiles** (the 0.25, 0.50 and 0.75 quartiles).  

To compute deciles (0.1, 0.2, 0.3, …., 0.9), use this:  
```{r chunk_11, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
quantile(my_data$Sepal.Length, seq(0, 1, 0.1))
```

To compute the interquartile range, type this:  
```{r chunk_12, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
IQR(my_data$Sepal.Length)
```

***

#### (3) Variance and standard deviation  

The variance represents the average squared deviation from the mean. The standard deviation is the square root of the variance. It measures the average deviation of the values, in the data, from the mean value.  

```{r chunk_13, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the variance
var(my_data$Sepal.Length)

# Compute the standard deviation == square root of the variance
sd(my_data$Sepal.Length)
```

***

#### (4) Median absolute deviation

The median absolute deviation (MAD) measures the deviation of the values, in the data, from the median value.  

```{r chunk_14, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the median
median(my_data$Sepal.Length)

# Compute the median absolute deviation
mad(my_data$Sepal.Length)
```

***

#### (5) Which measure to use?

  - **Range**. It’s not often used because it’s very sensitive to outliers.
  - **Interquartile range. It’s pretty robust to outliers. It’s used a lot in combination with the median.
  - **Variance**. It’s completely uninterpretable because it doesn’t use the same units as the data. It’s almost never used except as a mathematical tool
  - **Standard deviation**. This is the square root of the variance. It’s expressed in the same units as the data. The standard deviation is often used in the situation where the mean is the measure of central tendency.
  - **Median absolute deviation**. It’s a robust way to estimate the standard deviation, for data with outliers. It’s not used very often.

>In summary, the **IQR** and the **standard deviation** are the two most common measures used to report the variability of the data.  

***

## Computing an overall summary of a variable and an entire data frame  

#### (1) **`summary{base}`** function  

  >The function `summary{base}` can be used to display several statistic summaries of either one variable or an entire data frame.  

  * Summary of a single variable. Five values are returned:  
    the `mean`, `median`, `25th` and `75th` quartiles, `min` and `max` in one single line call:  
```{r chunk_15, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
summary(my_data$Sepal.Length)
```

  * 
    Summary of a data frame. In this case, the function summary{base} is automatically applied to each column. The format of the result depends on the type of the data contained in the column. For example:  
    
    + If the column is a numeric variable, mean, median, min, max and quartiles are returned.
    + If the column is a factor variable, the number of observations in each group is returned.  
```{r chunk_16, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
summary(my_data, digits = 1)
```

#### (2) **`sapply{base}`** function  

  >It’s also possible to use the function `sapply{base}` to apply a particular function over a list or vector. For instance, we can use it, to compute for each column in a data frame, the mean, sd, var, min, quantile, …  
  
```{r chunk_17, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute the mean of each column
sapply(my_data[, -5], mean)
```
  
```{r chunk_18, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute quartiles
sapply(my_data[, -5], quantile)
```

#### (3) **`stat.desc{pastecs}`** function  

The function `stat.desc{pastecs}`, provides other useful statistics including:

  - the **median**
  - the **mean**
  - the **standard error** on the mean (**SE.mean**)
  - the **confidence interval** of the mean (**CI.mean**) at the p level (**default is 0.95**)
  - the **variance** (**var**)
  - the **standard deviation** (**std.dev**)
  - the **variation coefficient** (**coef.var**) defined as the standard deviation divided by the mean  
  - Install pastecs package  
```{r chunk_19, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# install.packages("pastecs")
```
  - Use the function `stat.desc{pastec}` to compute descriptive statistics  
```{r chunk_20, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Compute descriptive statistics
library(pastecs)

res <- stat.desc(my_data[, -5])
round(res, 2)
```

***

## Case of missing values  

  >The function `summary{base}` can be used to display several statistic summaries of either one variable

For example, the `mean{base}` function will return `NA` if even only one value is missing in a vector. This can be avoided using the argument `na.rm = TRUE`, which tells to the function to remove any `NAs` before calculations. An example using the mean function is as follow:  

```{r chunk_21, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
mean(my_data$Sepal.Length, na.rm = TRUE)
```

***

## Graphical display of distributions  

### The R package **`{ggpubr}`** will be used to create graphs.  
<br>

#### (1) Installation and loading **{ggpubr}**  

  - Install the latest version from GitHub as follow:
```{r chunk_22, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# Install
# if(!require(devtools)) install.packages("devtools")
# devtools::install_github("kassambara/ggpubr")
```
  
  - Or, install from CRAN as follow:
```{r chunk_23, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
# install.packages("ggpubr")
```
  
  - Load ggpubr as follow:
```{r chunk_24, echo=TRUE, message=FALSE, warning=FALSE, include=TRUE}
library(ggpubr)
```
<br>

#### (2) Box plots

```{r chunk_25, echo=TRUE, fig.height=3.5, fig.width=3, message=FALSE, warning=FALSE, include=TRUE}
ggboxplot(my_data, y = "Sepal.Length", width = 0.5)
```
<br>

#### (3) Histogram
>Histograms show the number of observations that fall within specified divisions (i.e., bins).  

Histogram plot of Sepal.Length with mean line (dashed line):
```{r chunk_26, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
gghistogram(my_data, x = "Sepal.Length", bins = 9, add = "mean")
```
<br>

#### (4) Empirical cumulative distribution function (ECDF)

>ECDF is the fraction of data smaller than or equal to x. 

```{r chunk_27, echo=TRUE, fig.height=3.5, fig.width=3.5, message=FALSE, warning=FALSE, include=TRUE}
ggecdf(my_data, x = "Sepal.Length")
```
<br>

#### (5) Q-Q plots

>QQ plots is used to check whether the data is normally distributed. 

```{r chunk_28, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
ggqqplot(my_data, x = "Sepal.Length", color = 'black')
```

***

## Descriptive statistics by groups

#### To compute summary statistics by groups, the functions **`group_by{dplyr}`** and **`summarise{dplyr}`** can be used.

  * We want to group the data by Species and then:
      + compute the number of element in each group. R function: n()
      + compute the mean. R function mean()
      + and the standard deviation. R function sd()  
      
  >The function **`%>%`** is used to **chaine operations**.  
  
  * Install ddplyr as follow:  
  
```{r chunk_29, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# install.packages("dplyr")
```

  * Descriptive statistics by groups:  
  
```{r chunk_30, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
library(dplyr)

group_by(my_data, Species) %>% 
    summarise(
      count = n(), 
      mean = mean(Sepal.Length, na.rm = TRUE),
      sd = sd(Sepal.Length, na.rm = TRUE)
    )
```

  * Graphics for grouped data:  
  
```{r chunk_31, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
library("ggpubr")

# Box plot colored by groups: Species
ggboxplot(my_data, x = "Species", y = "Sepal.Length",
          color = "Species", palette = c("#00AFBB", "#E7B800", "#FC4E07"))
```

```{r chunk_32, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Stripchart colored by groups: Species
ggstripchart(my_data, x = "Species", y = "Sepal.Length", color = "Species",
            palette = c("#00AFBB", "#E7B800", "#FC4E07"), add = "mean_sd")
```

>Note that, when the number of observations per groups is **small**, it’s recommended to use **strip chart** compared to **box plots**.  

***

## Frequency tables

#### A **frequency table** (or **contingency table**) is used to describe **categorical** variables.  
#### It contains the counts at each combination of factor levels.
#### R function to generate tables: **`table{base}`**  


##### (1) Create some data  

Distribution of hair and eye color by sex of 592 students:  

```{r chunk_33, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Hair/eye color data
df <- as.data.frame(HairEyeColor)

hair_eye_col <- df[rep(row.names(df), df$Freq), 1:3]

rownames(hair_eye_col) <- 1:nrow(hair_eye_col)

head(hair_eye_col)
```

```{r chunk_34, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# hair/eye variables
Hair <- hair_eye_col$Hair
Eye <- hair_eye_col$Eye
```


##### (2) Simple frequency distribution: one categorical variable

  - Table of counts
```{r chunk_35, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Frequency distribution of hair color
table(Hair)
```

```{r chunk_36, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Frequency distribution of eye color
table(Eye)
```

  - Graphics: to create the graphics, we start by converting the table as a data frame.
```{r chunk_37, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Compute table and convert as data frame
( df <- as.data.frame(table(Hair)) )
str(df)
```

```{r chunk_38, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Visualize using bar plot
library(ggpubr)

ggbarplot(df, x = "Hair", y = "Freq")
```


##### (3) Two-way contingency table: Two categorical variables

```{r chunk_39, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
( tbl2 <- table(Hair , Eye) )
```

>It’s also possible to use the function **`xtabs{stats}`**, which will create cross tabulation of data frames with a formula interface.

```{r chunk_40, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
xtabs(~ Hair + Eye, data = hair_eye_col)
```

  - Graphics: to create the graphics, we start by converting the table as a data frame.
  
```{r chunk_41, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
( df <- as.data.frame(tbl2) )
# head(df)
```

```{r chunk_42, echo=TRUE, fig.height=4, fig.width=5, message=FALSE, warning=FALSE, include=TRUE}
# Visualize using bar plot
library(ggpubr)

ggbarplot(df, x = "Hair", y = "Freq", 
          color = "Eye", palette = c("brown", "blue", "gold", "green"))
```

```{r chunk_43, echo=TRUE, fig.height=4, fig.width=5, message=FALSE, warning=FALSE, include=TRUE}
# position dodge
ggbarplot(df, x = "Hair", y = "Freq",
          color = "Eye", position = position_dodge(),
          palette = c("brown", "blue", "gold", "green"))
```


##### (4) Multiway tables: More than two categorical variables

  - Hair and Eye color distributions by sex using xtabs():

```{r chunk_44, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
xtabs(~Hair + Eye + Sex, data = hair_eye_col)
```

  - You can also use the function ftable() [for flat contingency tables]. It returns a nice output compared to xtabs() when you have more than two variables:  
  
```{r chunk_45, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
ftable(Sex + Hair ~ Eye, data = hair_eye_col)
```


##### (5) Compute table margins and relative frequency

>Table margins correspond to the sums of counts along rows or columns of the table. Relative frequencies express table entries as proportions of table margins (i.e., row or column totals).

The function **`margin.table{base}`** and **`prop.table{base}`** can be used to compute table margins and relative frequencies, respectively.

  - Format of the functions:  
  **`margin.table(x, margin = NULL)`**  
  **`prop.table(x, margin = NULL)`**

    + x: table
    + margin: index number (1 for rows and 2 for columns)

  - compute table margins:  
```{r chunk_46, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
Hair <- hair_eye_col$Hair
Eye <- hair_eye_col$Eye

# Hair/Eye color table
( he.tbl <- table(Hair, Eye) )
```

```{r chunk_47, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Margin of rows
margin.table(he.tbl, 1)
```

```{r chunk_48, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Margin of columns
margin.table(he.tbl, 2)
```

  - Compute relative frequencies:  
```{r chunk_49, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Frequencies relative to row total
prop.table(he.tbl, 1)
```

```{r chunk_50, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
# Table of percentages
round(prop.table(he.tbl, 1), 2)*100
```

  - To express the frequencies relative to the grand total, use this:  
```{r chunk_51, echo=TRUE, fig.height=3.5, fig.width=4, message=FALSE, warning=FALSE, include=TRUE}
he.tbl/sum(he.tbl)
```

