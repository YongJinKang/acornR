---
title: "6-1. One-Sample T-test (parametric)"
output: html_document
---

### 1. What is one-sample t-test?

  - one-sample t-test is used to compare the mean of one sample to a known standard (or theoretical/hypothetical) mean (μ).

  - Generally, the theoretical mean comes from:

    + a previous experiment.  
      For example, compare whether the mean weight of mice differs from 200 mg, a value determined in a previous study.
                       
    + or from an experiment where you have control and treatment conditions.  
      If you express your data as `percent of control`, you can test whether the average value of treatment condition differs significantly from 100.

  - **Note** that, one-sample t-test can be used only, when the data are normally distributed.  
    This can be checked using `Shapiro-Wilk test`

***

### 2. Research questions and statistical hypotheses

  - Typical research questions are:
    + whether the mean (m) of the sample is equal to the theoretical mean (μ)?
    + whether the mean (m) of the sample is less than the theoretical mean (μ)?
    + whether the mean (m) of the sample is greater than the theoretical mean (μ)?
<p/>
  - In statistics, we can define the corresponding null hypothesis (H~0~) as follow:
    + H~0~ : m = μ
    + H~0~ : m ≤ μ
    + H~0~ : m ≥ μ
<p/>
  - The corresponding alternative hypotheses (H~1~) are as follow:
    + H~1~ : m ≠ μ (different)
    + H~1~ : m > μ (greater)
    + H~1~ : m < μ (less)
</p>
  - **Note** that:
    + H~0~) are called `two-tailed` tests if `different`
    + H~1~) are called `one-tailed` tests if `greater` or `less`

***

### 3. Formula of one-sample t-test

  - The `t-statistic` can be calculated as follow :

$$t = \frac{m - μ}{\frac{s}{\sqrt{n}}}$$
  - where,
    + `m` : the sample mean
    + `n` : the sample size
    + `s` : the sample standard deviation with `n−1` degrees of freedom
    + `μ` : the theoretical value
</p>
  - We can compute the `p-value` corresponding to the absolute value of the t-test statistics (`|t|`) for the degrees of freedom (`df`): `df = n−1`
  - How to interpret the results?
    + If the `p-value` is inferior or equal to the significance level 0.05,  we can reject the null hypothesis and accept the alternative hypothesis. 
    + In other words, we conclude that the sample mean is significantly different from the theoretical mean.

***

### 4. Visualize your data and compute one-sample t-test in R

  - Install `{ggpubr}` package for data visualization.
  - You can draw `R base graps` as described at this link: `R base graphs`.
  - Here, we’ll use the `{ggpubr}` package for an easy ggplot2-based data visualization

```{r code1, eval=FALSE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
# install.packages("ggpubr", quiet = TRUE)
```

  - R function to compute `one-sample t-test` To perform `one-sample t-test`, 
    the R function `t.test{stats}` can be used as follow:
    
    + `x` : a numeric vector containing your data values
    + `mu` : the theoretical mean. Default is 0 but you can change it.
    + `alternative` : the alternative hypothesis.  
      + allowed value is one of `two.sided` (default), `greater` or `less`.

```{r code2, eval=FALSE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
t.test(x, mu = 0, alternative = "two.sided")  # default: two-tailed test
```

  - Import your data into R :
    + Here, we’ll use an example data set containing the `weight of 10 mice`.  
    + We want to know, if the `average weight of the mice differs from 25g`?

```{r code3, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
set.seed(1234)

( 
  my_data <- data.frame(
                name = paste0(rep("M_", 10), 1:10), 
                weight = round(rnorm(10, 20, 2), 1)
              ) 
)
```

  - Check your data:
    
```{r code4, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
# Print the random sampled, 10 rows of the data
library(dplyr, quietly = TRUE)
sample_n(tbl = my_data, size = 10, replace = FALSE)

# Statistical summaries of weight
summary(my_data$weight)
```
  - 
    + `Min.` : the minimum value
    + `1st Qu.` : The first quartile. 25% of values are lower than this.
    + `Median` : the median value. Half the values are lower; half are higher.
    + `3rd Qu.` : the third quartile. 75% of values are higher than this.
    + `Max.` : the maximum value
<p/>
  - Visualize your data using `box plots`

```{r code5, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE, fig.width=3, fig.height=3.5}
# install.packages('ggpubr', dependencies = TRUE)
library(ggpubr, quietly = TRUE)

ggboxplot(
      my_data$weight,
      ylab = "Weight (g)", 
      xlab = FALSE,
      ggtheme = theme_minimal()
  )
```

  - Preleminary test to check `one-sample t-test` assumptions
    + Is this a large sample? - No, because n < 30.
    + Since the sample size is not large enough (less than 30, central limit theorem), we need to check whether the data follow a normal distribution.
<p/>
  - How to check the normality?
    + Briefly, it’s possible to use the Shapiro-Wilk normality test and to look at the normality plot.
    + Shapiro-Wilk test :
      + H~0~ : the data are *normally* distributed
      + H~1~ : the data are *not* normally distributed
    + Visual inspection of the data normality using Q-Q plots (quantile-quantile plots). 
      Q-Q plot draws the correlation between a given sample and the normal distribution.
      
```{r code6, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(my_data$weight)
```

  - From the output, 
    + the p-value is greater than the significance level 0.05 implying that the distribution of the data are not significantly different from normal distribtion. 
    + In other words, we can assume the normality.

```{r code7, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE, fig.width=4, fig.height=3.5}
library("ggpubr", quietly = TRUE)

ggqqplot(my_data$weight, ylab = "Men's weight", ggtheme = theme_minimal())
```

  - From the normality plots, we conclude that the data may come from normal distributions.
        
  - *Note* that, if the data are not normally distributed, it’s recommended to use the non parametric one-sample Wilcoxon rank test.


  - Compute `one-sample t-test`
    + We want to know, if the average weight of the mice differs from 25g (two-tailed test)?

```{r code8, eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
# One-sample t-test
( res <- t.test(my_data$weight, mu = 25) )
```

  - In the result above :
    + `t`                 : the t-test statistic value (t = -9.078),
    + `df`                : the degrees of freedom (df= 9),
    + `p-value`           : the significance level of the t-test (p-value = $7.95310^{-6}$).
    + `conf.int`          : the confidence interval of the mean at 95% (conf.int = [17.8172, 20.6828]);
    + `sample estimates`  : he mean value of the sample (mean = 19.25).

  - *Note* that:
    + if you want to test whether the mean weight of mice is less than 25g (one-tailed test), type this:

```{r code9, eval=FALSE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
        t.test(my_data$weight, mu = 25, alternative = "less")
```
  
  -
    + Or, if you want to test whether the mean weight of mice is greater than 25g (one-tailed test), type this:

````{r code10, eval=FALSE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
        t.test(my_data$weight, mu = 25, alternative = "greater")
````

  - Interpretation of the result
    + The `p-value` of the test is $7.95310^{-6}$, which is `less than` the significance level `alpha = 0.05`. 
    + We can conclude that the `mean weight` of the mice is `significantly different` from 25g with a `p-value` = $7.95310^{-6}$.

  - Access to the values returned by `t.test{stats}` function
    + The result of `t.test{stats}` function is a list containing the following components:
      + `statistic` : the value of the t test statistics
      + `parameter` : the degrees of freedom for the t test statistics
      + `p.value` : the p-value for the test
      + `conf.int` : a confidence interval for the mean appropriate to the specified alternative hypothesis.
      + `estimate` : the means of the two groups being compared (in the case of independent t test) or difference in means (in the case of paired t test).
    + The format of the R code to use for getting these values is as follow :

```{r}
    # printing the p-value
    res$p.value
    
    # printing the mean
    res$estimate
    
    # printing the confidence interval
    res$conf.int
```

